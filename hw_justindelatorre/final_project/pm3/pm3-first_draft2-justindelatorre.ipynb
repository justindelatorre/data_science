{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PM3: First Draft and Progress Report ([presentation link](https://docs.google.com/presentation/d/1x0f_TOlJKiu6sIVaI-RIBynmladd02lt-9ZwkZsvPSE/edit#slide=id.p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##<i>Part I: Current Project Status</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><b>tl;dr</b>: I've added more data to include more presidents and speeches, and labelling political affiliation on a gradient is too hard, so I'm going to switch to modeling other things.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Roadblocks\n",
    "\n",
    "Since the last project milestone, I've obtained more data (which will be presented shortly) and, as a result of playing around with the original dataset, am strongly considering slightly tweaking my project objectives. Analyzing how conservative or liberal a president may be based on political rhetoric would likely involve creating a custom sentiment mapping, and while I have some familiarity with NLTK, I believe that a custom job would probably be beyond the scope of my skills at this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###New Data\n",
    "\n",
    "As such, I've obtained a few other pieces of data that may allow me to do something similar to my original goal. These data (from various online sources) contain information like a president's political party, religious affiliation, age at inauguration and at death, and each president's aggregate rank according to various scholars.\n",
    "\n",
    "In addition, I've also expanded the corpus of text to analyze to include state of the union addresses as well. Some presidents - primarily those who were not elected to office, mainly vice-presidents who assumed the position after their predecessors had either passed away or resigned - did not deliver inaugural addresses, and so I included more speeches to ensure more presidents were included in the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Changes in Project Scope and Objectives\n",
    "\n",
    "With these new data, I now hope to use political rhetoric to model the newly-introduced categorical and continuous labels (e.g., party, religion, ranking) and potentiall gain insight to the following questions, among others:\n",
    "<ul>\n",
    "<li>What common language, themes, and phrases do our greatest presidents have in common in their rhetoric?</li>\n",
    "<li>Is there a quanitifiable relationship between these rhetorical traits and how great a president is perceived to be?</li>\n",
    "<li>Does a president's specific religious background affect the language used in speeches?</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##<i>Part II: Previous Milestone (PM2): Data Ready</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>This section contains mostly data pre-processing and initial exploratory data analysis. If you're interested in what I've done since the previous milestone deadline, feel free to skip ahead to <b>Part III</b>.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data Sources:</b>\n",
    "<ul>\n",
    "<li>Inaugural Addresses and States of the Union: Project Gutenberg</li>\n",
    "<li>[Presidential Data](http://www.infoplease.com/ipa/A0194030.html): Infoplease</li>\n",
    "<li>[Presidential Rankings](https://en.wikipedia.org/wiki/Historical_rankings_of_Presidents_of_the_United_States#Five_Thirty_Eight_analysis): Wikipedia/538</li>\n",
    "</ul>\n",
    "\n",
    "Structured data can be found [here](https://docs.google.com/spreadsheets/d/1cujFV5JLRivY-k6LMEDCP8_zapHUtwNCdb9Qr8h2gOQ/edit#gid=0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####<i>Step 1: Pre-processing - Parsing Speeches</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import all the packages we'll need to clean the data:\n",
    "<ul>\n",
    "<li><code>re</code> for regular expression functions</li>\n",
    "<li><code>pprint</code> to make printing more readable</li>\n",
    "<li><code>string</code> to clean string values</li>\n",
    "<li><code>pandas</code> because <i>duh</i></li>\n",
    "<li><code>numpy</code> because math</li>\n",
    "<li><code>matplotlib.pyplot</code> for charts</li>\n",
    "<li><code>CountVectorizer</code> for parsing tokens and removing stop words</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import pprint as pp\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll open the text files and read them into Python objects that can be parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inaugural speech text\n",
    "inaugural = open('../data/inaugural.txt', 'r')\n",
    "inaugural_text = inaugural.read()\n",
    "\n",
    "# State of the Union text\n",
    "sotu = open('../data/sotu.txt', 'r')\n",
    "sotu_text = sotu.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll parse the inaugural speech data using <code>re</code> modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create list of speech titles which will act as speech IDs\n",
    "raw_speech_id_list = re.findall(r'\\*\\s\\*\\s\\*\\s\\*\\s\\*([\\w\\s\\,\\.]+)ADDRESS',\n",
    "                                inaugural_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a <code>string</code> method (<code>strip</code>) to remove extraneous characters from the title list first. Later, we'll create a <code>dict</code> object that will have each title as a key and each full speech text as a value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stripped_id_list = [string.strip(title, \"\\r\\n \") for title in raw_speech_id_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on to cleaning the speech text since we've cleaned the titles.\n",
    "\n",
    "All the speeches in the text file are separated by \\* \\* \\* \\* \\* delimiters, so we'll use <code>re.split</code> again to extract all the text between the delimiters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_speech = re.split(r'\\*\\s\\*\\s\\*\\s\\*\\s\\*', inaugural_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use <code>re.sub</code> to replace the \"Transcriber's Notes\" because we only want the speech text for each inaugural address. We'll also ignore the first and last elements in the <code>raw_speech</code> list because it isn't actually speech text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "speeches = [re.sub(r'^([\\w\\W\\s]+)\\]', \"\", speech) for speech in raw_speech[1:len(raw_speech)-1]]\n",
    "\n",
    "print len(speeches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll use a combination of <code>re.sub</code> and <code>string.strip</code> to clean up all the extra spaces and newline characters in each speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "clean_speeches = []\n",
    "[clean_speeches.append(re.sub(r'\\r\\n',\n",
    "                              \" \",\n",
    "                              string.strip(speech,\n",
    "                                           \"\\r\\n\"))) \n",
    " for speech in speeches]\n",
    "\n",
    "print len(clean_speeches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like most of the works is done, but you'll see that the last three speeches still contain extranous test (mostly speech IDs) that should be removed, so we'll take the last use <code>re.sub</code> on the last three to extract the last bit of cruft before moving on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_speeches_inaugural = [re.sub(r'([A-Z0-9\\,\\.\\s]+)\\s{3}', \"\", speech) \n",
    "                            for speech in clean_speeches]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the inaugural data is clean, let's follow similar steps to clean the State of the Union (SOTU) speeches. Again, we'll use <code>re</code> modules to extract the text.\n",
    "\n",
    "First, we'll create a list of titles that will serve as speech IDs. Rather than extracting using Python, however, it'll be easier to just copy and paste the SOTU titles and load it into a Python list :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GEORGE WASHINGTON, STATE OF THE UNION ADDRESS',\n",
      " 'GEORGE WASHINGTON, STATE OF THE UNION ADDRESS']\n"
     ]
    }
   ],
   "source": [
    "raw_speech_id_list_sotu = [\n",
    "'George Washington, State of the Union Address',\n",
    "'George Washington, State of the Union Address',\n",
    "'George Washington, State of the Union Address',\n",
    "'George Washington, State of the Union Address',\n",
    "'George Washington, State of the Union Address',\n",
    "'George Washington, State of the Union Address',\n",
    "'George Washington, State of the Union Address',\n",
    "'George Washington, State of the Union Address',\n",
    "'John Adams, State of the Union Address',\n",
    "'John Adams, State of the Union Address',\n",
    "'John Adams, State of the Union Address',\n",
    "'John Adams, State of the Union Address',\n",
    "'Thomas Jefferson, State of the Union Address',\n",
    "'Thomas Jefferson, State of the Union Address',\n",
    "'Thomas Jefferson, State of the Union Address',\n",
    "'Thomas Jefferson, State of the Union Address',\n",
    "'Thomas Jefferson, State of the Union Address',\n",
    "'Thomas Jefferson, State of the Union Address',\n",
    "'Thomas Jefferson, State of the Union Address',\n",
    "'Thomas Jefferson, State of the Union Address',\n",
    "'James Madison, State of the Union Address',\n",
    "'James Madison, State of the Union Address',\n",
    "'James Madison, State of the Union Address',\n",
    "'James Madison, State of the Union Address',\n",
    "'James Madison, State of the Union Address',\n",
    "'James Madison, State of the Union Address',\n",
    "'James Madison, State of the Union Address',\n",
    "'James Madison, State of the Union Address',\n",
    "'James Monroe, State of the Union Address',\n",
    "'James Monroe, State of the Union Address',\n",
    "'James Monroe, State of the Union Address',\n",
    "'James Monroe, State of the Union Address',\n",
    "'James Monroe, State of the Union Address',\n",
    "'James Monroe, State of the Union Address',\n",
    "'James Monroe, State of the Union Address',\n",
    "'James Monroe, State of the Union Address',\n",
    "'John Quincy Adams, State of the Union Address',\n",
    "'John Quincy Adams, State of the Union Address',\n",
    "'John Quincy Adams, State of the Union Address',\n",
    "'John Quincy Adams, State of the Union Address',\n",
    "'Andrew Jackson, State of the Union Address',\n",
    "'Andrew Jackson, State of the Union Address',\n",
    "'Andrew Jackson, State of the Union Address',\n",
    "'Andrew Jackson, State of the Union Address',\n",
    "'Andrew Jackson, State of the Union Address',\n",
    "'Andrew Jackson, State of the Union Address',\n",
    "'Andrew Jackson, State of the Union Address',\n",
    "'Andrew Jackson, State of the Union Address',\n",
    "'Martin van Buren, State of the Union Address',\n",
    "'Martin van Buren, State of the Union Address',\n",
    "'Martin van Buren, State of the Union Address',\n",
    "'Martin van Buren, State of the Union Address',\n",
    "'John Tyler, State of the Union Address',\n",
    "'John Tyler, State of the Union Address',\n",
    "'John Tyler, State of the Union Address',\n",
    "'John Tyler, State of the Union Address',\n",
    "'James Polk, State of the Union Address',\n",
    "'James Polk, State of the Union Address',\n",
    "'James Polk, State of the Union Address',\n",
    "'James Polk, State of the Union Address',\n",
    "'Zachary Taylor, State of the Union Address',\n",
    "'Millard Fillmore, State of the Union Address',\n",
    "'Millard Fillmore, State of the Union Address',\n",
    "'Millard Fillmore, State of the Union Address',\n",
    "'Franklin Pierce, State of the Union Address',\n",
    "'Franklin Pierce, State of the Union Address',\n",
    "'Franklin Pierce, State of the Union Address',\n",
    "'Franklin Pierce, State of the Union Address',\n",
    "'James Buchanan, State of the Union Address',\n",
    "'James Buchanan, State of the Union Address',\n",
    "'James Buchanan, State of the Union Address',\n",
    "'James Buchanan, State of the Union Address',\n",
    "'Abraham Lincoln, State of the Union Address',\n",
    "'Abraham Lincoln, State of the Union Address',\n",
    "'Abraham Lincoln, State of the Union Address',\n",
    "'Abraham Lincoln, State of the Union Address',\n",
    "'Andrew Johnson, State of the Union Address',\n",
    "'Andrew Johnson, State of the Union Address',\n",
    "'Andrew Johnson, State of the Union Address',\n",
    "'Andrew Johnson, State of the Union Address',\n",
    "'Ulysses S. Grant, State of the Union Address',\n",
    "'Ulysses S. Grant, State of the Union Address',\n",
    "'Ulysses S. Grant, State of the Union Address',\n",
    "'Ulysses S. Grant, State of the Union Address',\n",
    "'Ulysses S. Grant, State of the Union Address',\n",
    "'Ulysses S. Grant, State of the Union Address',\n",
    "'Ulysses S. Grant, State of the Union Address',\n",
    "'Ulysses S. Grant, State of the Union Address',\n",
    "'Rutherford B. Hayes, State of the Union Address',\n",
    "'Rutherford B. Hayes, State of the Union Address',\n",
    "'Rutherford B. Hayes, State of the Union Address',\n",
    "'Rutherford B. Hayes, State of the Union Address',\n",
    "'Chester A. Arthur, State of the Union Address',\n",
    "'Chester A. Arthur, State of the Union Address',\n",
    "'Chester A. Arthur, State of the Union Address',\n",
    "'Chester A. Arthur, State of the Union Address',\n",
    "'Grover Cleveland, State of the Union Address',\n",
    "'Grover Cleveland, State of the Union Address',\n",
    "'Grover Cleveland, State of the Union Address',\n",
    "'Grover Cleveland, State of the Union Address',\n",
    "'Benjamin Harrison, State of the Union Address',\n",
    "'Benjamin Harrison, State of the Union Address',\n",
    "'Benjamin Harrison, State of the Union Address',\n",
    "'Benjamin Harrison, State of the Union Address',\n",
    "'William McKinley, State of the Union Address',\n",
    "'William McKinley, State of the Union Address',\n",
    "'William McKinley, State of the Union Address',\n",
    "'William McKinley, State of the Union Address',\n",
    "'Theodore Roosevelt, State of the Union Address',\n",
    "'Theodore Roosevelt, State of the Union Address',\n",
    "'Theodore Roosevelt, State of the Union Address',\n",
    "'Theodore Roosevelt, State of the Union Address',\n",
    "'Theodore Roosevelt, State of the Union Address',\n",
    "'Theodore Roosevelt, State of the Union Address',\n",
    "'Theodore Roosevelt, State of the Union Address',\n",
    "'Theodore Roosevelt, State of the Union Address',\n",
    "'William H. Taft, State of the Union Address',\n",
    "'William H. Taft, State of the Union Address',\n",
    "'William H. Taft, State of the Union Address',\n",
    "'William H. Taft, State of the Union Address',\n",
    "'Woodrow Wilson, State of the Union Address',\n",
    "'Woodrow Wilson, State of the Union Address',\n",
    "'Woodrow Wilson, State of the Union Address',\n",
    "'Woodrow Wilson, State of the Union Address',\n",
    "'Woodrow Wilson, State of the Union Address',\n",
    "'Woodrow Wilson, State of the Union Address',\n",
    "'Woodrow Wilson, State of the Union Address',\n",
    "'Woodrow Wilson, State of the Union Address',\n",
    "'Warren Harding, State of the Union Address',\n",
    "'Warren Harding, State of the Union Address',\n",
    "'Calvin Coolidge, State of the Union Address',\n",
    "'Calvin Coolidge, State of the Union Address',\n",
    "'Calvin Coolidge, State of the Union Address',\n",
    "'Calvin Coolidge, State of the Union Address',\n",
    "'Calvin Coolidge, State of the Union Address',\n",
    "'Calvin Coolidge, State of the Union Address',\n",
    "'Herbert Hoover, State of the Union Address',\n",
    "'Herbert Hoover, State of the Union Address',\n",
    "'Herbert Hoover, State of the Union Address',\n",
    "'Herbert Hoover, State of the Union Address',\n",
    "'Franklin D. Roosevelt, State of the Union Address',\n",
    "'Franklin D. Roosevelt, State of the Union Address',\n",
    "'Franklin D. Roosevelt, State of the Union Address',\n",
    "'Franklin D. Roosevelt, State of the Union Address',\n",
    "'Franklin D. Roosevelt, State of the Union Address',\n",
    "'Franklin D. Roosevelt, State of the Union Address',\n",
    "'Franklin D. Roosevelt, State of the Union Address',\n",
    "'Franklin D. Roosevelt, State of the Union Address',\n",
    "'Franklin D. Roosevelt, State of the Union Address',\n",
    "'Franklin D. Roosevelt, State of the Union Address',\n",
    "'Franklin D. Roosevelt, State of the Union Address',\n",
    "'Franklin D. Roosevelt, State of the Union Address',\n",
    "'Harry S. Truman, State of the Union Address',\n",
    "'Harry S. Truman, State of the Union Address',\n",
    "'Harry S. Truman, State of the Union Address',\n",
    "'Harry S. Truman, State of the Union Address',\n",
    "'Harry S. Truman, State of the Union Address',\n",
    "'Harry S. Truman, State of the Union Address',\n",
    "'Harry S. Truman, State of the Union Address',\n",
    "'Harry S. Truman, State of the Union Address',\n",
    "'Dwight D. Eisenhower, State of the Union Address',\n",
    "'Dwight D. Eisenhower, State of the Union Address',\n",
    "'Dwight D. Eisenhower, State of the Union Address',\n",
    "'Dwight D. Eisenhower, State of the Union Address',\n",
    "'Dwight D. Eisenhower, State of the Union Address',\n",
    "'Dwight D. Eisenhower, State of the Union Address',\n",
    "'Dwight D. Eisenhower, State of the Union Address',\n",
    "'Dwight D. Eisenhower, State of the Union Address',\n",
    "'Dwight D. Eisenhower, State of the Union Address',\n",
    "'John F. Kennedy, State of the Union Address',\n",
    "'John F. Kennedy, State of the Union Address',\n",
    "'John F. Kennedy, State of the Union Address',\n",
    "'Lyndon B. Johnson, State of the Union Address',\n",
    "'Lyndon B. Johnson, State of the Union Address',\n",
    "'Lyndon B. Johnson, State of the Union Address',\n",
    "'Lyndon B. Johnson, State of the Union Address',\n",
    "'Lyndon B. Johnson, State of the Union Address',\n",
    "'Lyndon B. Johnson, State of the Union Address',\n",
    "'Richard Nixon, State of the Union Address',\n",
    "'Richard Nixon, State of the Union Address',\n",
    "'Richard Nixon, State of the Union Address',\n",
    "'Richard Nixon, State of the Union Address',\n",
    "'Richard Nixon, State of the Union Address',\n",
    "'Gerald R. Ford, State of the Union Address',\n",
    "'Gerald R. Ford, State of the Union Address',\n",
    "'Gerald R. Ford, State of the Union Address',\n",
    "'Jimmy Carter, State of the Union Address',\n",
    "'Jimmy Carter, State of the Union Address',\n",
    "'Jimmy Carter, State of the Union Address',\n",
    "'Jimmy Carter, State of the Union Address',\n",
    "'Ronald Reagan, State of the Union Address',\n",
    "'Ronald Reagan, State of the Union Address',\n",
    "'Ronald Reagan, State of the Union Address',\n",
    "'Ronald Reagan, State of the Union Address',\n",
    "'Ronald Reagan, State of the Union Address',\n",
    "'Ronald Reagan, State of the Union Address',\n",
    "'Ronald Reagan, State of the Union Address',\n",
    "'George H.W. Bush, State of the Union Address',\n",
    "'George H.W. Bush, State of the Union Address',\n",
    "'George H.W. Bush, State of the Union Address',\n",
    "'William J. Clinton, State of the Union Address',\n",
    "'William J. Clinton, State of the Union Address',\n",
    "'William J. Clinton, State of the Union Address',\n",
    "'William J. Clinton, State of the Union Address',\n",
    "'William J. Clinton, State of the Union Address',\n",
    "'William J. Clinton, State of the Union Address',\n",
    "'William J. Clinton, State of the Union Address',\n",
    "'George W. Bush, State of the Union Address',\n",
    "'George W. Bush, State of the Union Address',\n",
    "'George W. Bush, State of the Union Address',\n",
    "'George W. Bush, State of the Union Address',\n",
    "'George W. Bush, State of the Union Address',\n",
    "'George W. Bush, State of the Union Address',\n",
    "'George W. Bush, State of the Union Address'\n",
    "]\n",
    "\n",
    "# Capitalize speech IDs to conform to Inaugural Address data\n",
    "raw_speech_id_list_sotu_caps = []\n",
    "[raw_speech_id_list_sotu_caps.append(item.upper()) for item in raw_speech_id_list_sotu]\n",
    "\n",
    "pp.pprint(raw_speech_id_list_sotu_caps[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GEORGE WASHINGTON, STATE OF THE UNION',\n",
      " 'GEORGE WASHINGTON, STATE OF THE UNION']\n"
     ]
    }
   ],
   "source": [
    "# Parse out speech IDs and append them to a list\n",
    "speech_id_list_sotu = []\n",
    "[speech_id_list_sotu.append(re.findall(r'^(.*?)\\sADDRESS',\n",
    "                                       speech)[0])\n",
    " for speech in raw_speech_id_list_sotu_caps]\n",
    "\n",
    "pp.pprint(speech_id_list_sotu[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine the speech IDs into a single list\n",
    "title_list = stripped_id_list + speech_id_list_sotu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the hard part: let's grab the actual speech text for each State of the Union speech. First, we'll split the full text file; each speech is separated by \\*\\*\\*, so we'll split using that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_speech_sotu = re.split(r'\\*\\*\\*\\r\\n\\r\\n', sotu_text)\n",
    "\n",
    "# Actual speeches start at index 4 and end at index -3\n",
    "raw_speech_sotu = raw_speech_sotu[4:-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clean things up just a bit more, we'll remove the title information in each speech text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n"
     ]
    }
   ],
   "source": [
    "clean_speeches_sotu = []\n",
    "[clean_speeches_sotu.append(re.findall(r'[0-9]{4}([\\w\\W\\s\\S]+)$',\n",
    "                            speech)[0])\n",
    "                            for speech in raw_speech_sotu]\n",
    "\n",
    "print len(clean_speeches_sotu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that both sets of speeches have been properly cleaned, we'll add them both together, then run the aggregated set of speeches through <code>CountVectorizer</code> to tokenize all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_speeches_all = clean_speeches_inaugural + clean_speeches_sotu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(decode_error = 'ignore', stop_words='english')\n",
    "vect.fit(clean_speeches_all)\n",
    "raw_feature_names = [token.encode('ascii','ignore') for token in vect.get_feature_names()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we'll create a document-term matrix that will allow us to then create a <code>DataFrame</code> that counts the number of times each token appears in each speech. We'll also remove all non-word tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtm = vect.transform(clean_speeches_all)\n",
    "dtm.toarray()\n",
    "raw_df = pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jay/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "df = raw_df.iloc[:,raw_feature_names.index('______________________')+1:]\n",
    "\n",
    "df['title_id'] = title_list\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew! We're done with that part. There's still more to do though!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####<i>Step 2: Pre-processing - Joining Data and Selecting Features</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll load the other datasets into <code>DataFrame</code>s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load president details into DataFrame\n",
    "df_prez = pd.read_csv('../data/presidents.csv')\n",
    "\n",
    "# Load aggregated president rankings into DataFrame\n",
    "df_rankings = pd.read_csv('../data/prez_rankings_538.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the full dataset pulls together data from multiple sources, we'll need to very strategic about what data we join together to create the dataset that will be most effectively interpreted by the models we will use. Ideally, we'd like to be able join all the disparate data together using some common key ID, which unfortunately is not available, so it will need to be manufactured first before the data can be combined. Luckily, the <code>presidents.csv</code> file has an <code>id</code> feature that can be used to create other <code>id</code> in the other datasets.\n",
    "\n",
    "It would likely be more difficult to do this programmatically, so, in the interest of keeping things simple, let's write the current <code>DataFrame</code>s to files and manually tag each of the speeches with each president's <code>id</code>. A much larger dataset would probably require writing code to assign <code>id</code>s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write speech DataFrame data to a file\n",
    "file_df = open('../data/df.csv', 'w')\n",
    "for row in df.title_id:\n",
    "    file_df.write(row)\n",
    "    file_df.write('\\n')\n",
    "\n",
    "file_df.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So after a little manual labor thanks to magic data entry elves, we can re-load the speech data into the <code>DataFrame</code>s, now with each president's respective <code>id</code>. Then we'll replace the existing columns in the <code>DataFrame</code> with the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id               name            speech  a14  aaa  aaron  abandon  \\\n",
      "0   1  GEORGE WASHINGTON   FIRST INAUGURAL    0    0      0        0   \n",
      "1   1  GEORGE WASHINGTON  SECOND INAUGURAL    0    0      0        0   \n",
      "2   2         JOHN ADAMS         INAUGURAL    0    0      0        0   \n",
      "3   3   THOMAS JEFFERSON   FIRST INAUGURAL    0    0      0        1   \n",
      "4   3   THOMAS JEFFERSON  SECOND INAUGURAL    0    0      0        0   \n",
      "\n",
      "   abandoned  abandoning  abandonment   ...     zimbabwe  zimbabwean  zinc  \\\n",
      "0          0           0            0   ...            0           0     0   \n",
      "1          0           0            0   ...            0           0     0   \n",
      "2          1           0            0   ...            0           0     0   \n",
      "3          0           0            0   ...            0           0     0   \n",
      "4          0           0            0   ...            0           0     0   \n",
      "\n",
      "   zion  zollverein  zone  zones  zoological  zooming  zuloaga  \n",
      "0     0           0     0      0           0        0        0  \n",
      "1     0           0     0      0           0        0        0  \n",
      "2     0           0     0      0           0        0        0  \n",
      "3     0           0     0      0           0        0        0  \n",
      "4     0           0     0      0           0        0        0  \n",
      "\n",
      "[5 rows x 22745 columns]\n",
      "# of records: 269 | # of tokens: 22745\n"
     ]
    }
   ],
   "source": [
    "# Load newly-tagged data\n",
    "df_with_id = pd.read_csv('../data/df_with_id.csv')\n",
    "\n",
    "# Concat loaded DataFrame to old DataFrame\n",
    "df = pd.concat([df_with_id, df.iloc[:,9:]], axis=1)\n",
    "\n",
    "print df.head()\n",
    "\n",
    "print '# of records: ' + str(len(df)) + ' | # of tokens: ' + str(len(df.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're finally done with our preliminary <code>DataFrame</code>, so now let's load the last of the data (personal details and rankings for each president)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load president details into DataFrame\n",
    "df_prez = pd.read_csv('../data/presidents.csv')\n",
    "\n",
    "# Load aggregated president rankings into DataFrame\n",
    "df_rankings = pd.read_csv('../data/prez_rankings_538.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name_and_party</th>\n",
       "      <th>name</th>\n",
       "      <th>party_letter</th>\n",
       "      <th>party_name</th>\n",
       "      <th>term</th>\n",
       "      <th>state_of_birth</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>death_date</th>\n",
       "      <th>religion</th>\n",
       "      <th>age_inauguration</th>\n",
       "      <th>age_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1</td>\n",
       "      <td> Washington (F)3</td>\n",
       "      <td> Washington </td>\n",
       "      <td>  F</td>\n",
       "      <td>            Federalist</td>\n",
       "      <td> 1789–1797</td>\n",
       "      <td>   Va.</td>\n",
       "      <td>  2/22/1732</td>\n",
       "      <td> 12/14/1799</td>\n",
       "      <td> Episcopalian</td>\n",
       "      <td> 57</td>\n",
       "      <td> 67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 2</td>\n",
       "      <td>    J. Adams (F)</td>\n",
       "      <td>   J. Adams </td>\n",
       "      <td>  F</td>\n",
       "      <td>            Federalist</td>\n",
       "      <td> 1797–1801</td>\n",
       "      <td> Mass.</td>\n",
       "      <td> 10/30/1735</td>\n",
       "      <td>   7/4/1826</td>\n",
       "      <td>    Unitarian</td>\n",
       "      <td> 61</td>\n",
       "      <td> 90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 3</td>\n",
       "      <td>  Jefferson (DR)</td>\n",
       "      <td>  Jefferson </td>\n",
       "      <td> DR</td>\n",
       "      <td> Democratic Republican</td>\n",
       "      <td> 1801–1809</td>\n",
       "      <td>   Va.</td>\n",
       "      <td>  4/13/1743</td>\n",
       "      <td>   7/4/1826</td>\n",
       "      <td>        Deist</td>\n",
       "      <td> 57</td>\n",
       "      <td> 83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 4</td>\n",
       "      <td>    Madison (DR)</td>\n",
       "      <td>    Madison </td>\n",
       "      <td> DR</td>\n",
       "      <td> Democratic Republican</td>\n",
       "      <td> 1809–1817</td>\n",
       "      <td>   Va.</td>\n",
       "      <td>  3/16/1751</td>\n",
       "      <td>  6/28/1836</td>\n",
       "      <td> Episcopalian</td>\n",
       "      <td> 57</td>\n",
       "      <td> 85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 5</td>\n",
       "      <td>     Monroe (DR)</td>\n",
       "      <td>     Monroe </td>\n",
       "      <td> DR</td>\n",
       "      <td> Democratic Republican</td>\n",
       "      <td> 1817–1825</td>\n",
       "      <td>   Va.</td>\n",
       "      <td>  4/28/1758</td>\n",
       "      <td>   7/4/1831</td>\n",
       "      <td> Episcopalian</td>\n",
       "      <td> 58</td>\n",
       "      <td> 73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   name_and_party         name party_letter             party_name  \\\n",
       "0   1  Washington (F)3  Washington             F             Federalist   \n",
       "1   2     J. Adams (F)    J. Adams             F             Federalist   \n",
       "2   3   Jefferson (DR)   Jefferson            DR  Democratic Republican   \n",
       "3   4     Madison (DR)     Madison            DR  Democratic Republican   \n",
       "4   5      Monroe (DR)      Monroe            DR  Democratic Republican   \n",
       "\n",
       "        term state_of_birth  birth_date  death_date      religion  \\\n",
       "0  1789–1797            Va.   2/22/1732  12/14/1799  Episcopalian   \n",
       "1  1797–1801          Mass.  10/30/1735    7/4/1826     Unitarian   \n",
       "2  1801–1809            Va.   4/13/1743    7/4/1826         Deist   \n",
       "3  1809–1817            Va.   3/16/1751   6/28/1836  Episcopalian   \n",
       "4  1817–1825            Va.   4/28/1758    7/4/1831  Episcopalian   \n",
       "\n",
       "   age_inauguration age_death  \n",
       "0                57        67  \n",
       "1                61        90  \n",
       "2                57        83  \n",
       "3                57        85  \n",
       "4                58        73  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prez.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rank_aggregate</th>\n",
       "      <th>president</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 16</td>\n",
       "      <td> 1</td>\n",
       "      <td>       Abraham Lincoln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 32</td>\n",
       "      <td> 2</td>\n",
       "      <td> Franklin D. Roosevelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>  1</td>\n",
       "      <td> 3</td>\n",
       "      <td>     George Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 26</td>\n",
       "      <td> 4</td>\n",
       "      <td>    Theodore Roosevelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>  3</td>\n",
       "      <td> 5</td>\n",
       "      <td>      Thomas Jefferson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  rank_aggregate              president\n",
       "0  16               1        Abraham Lincoln\n",
       "1  32               2  Franklin D. Roosevelt\n",
       "2   1               3      George Washington\n",
       "3  26               4     Theodore Roosevelt\n",
       "4   3               5       Thomas Jefferson"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rankings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is loaded, we can use <code>pd.merge</code> to create our master <code>DataFrame</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id             name_x            speech  a14  aaa  aaron  abandon  \\\n",
      "0   1  GEORGE WASHINGTON   FIRST INAUGURAL    0    0      0        0   \n",
      "0   1  GEORGE WASHINGTON  SECOND INAUGURAL    0    0      0        0   \n",
      "\n",
      "   abandoned  abandoning  abandonment    ...           name_y  party_letter  \\\n",
      "0          0           0            0    ...      Washington              F   \n",
      "0          0           0            0    ...      Washington              F   \n",
      "\n",
      "   party_name     term_y  state_of_birth  birth_date  death_date  \\\n",
      "0  Federalist  1789–1797             Va.   2/22/1732  12/14/1799   \n",
      "0  Federalist  1789–1797             Va.   2/22/1732  12/14/1799   \n",
      "\n",
      "     religion_y  age_inauguration  age_death  \n",
      "0  Episcopalian                57         67  \n",
      "0  Episcopalian                57         67  \n",
      "\n",
      "[2 rows x 22756 columns]\n"
     ]
    }
   ],
   "source": [
    "# Join presidential details DataFrame\n",
    "df_merge_details = pd.merge(df, df_prez, on=\"id\", how=\"left\", left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id           name_x              speech  a14  aaa  aaron  abandon  \\\n",
      "8  35  JOHN F. KENNEDY           INAUGURAL    0    0      0        0   \n",
      "8  35  JOHN F. KENNEDY  STATE OF THE UNION    0    0      0        0   \n",
      "8  35  JOHN F. KENNEDY  STATE OF THE UNION    0    0      0        1   \n",
      "8  35  JOHN F. KENNEDY  STATE OF THE UNION    0    0      0        1   \n",
      "\n",
      "   abandoned  abandoning  abandonment       ...         party_name     term_y  \\\n",
      "8          0           0            0       ...         Democratic  1961–1963   \n",
      "8          0           0            0       ...         Democratic  1961–1963   \n",
      "8          0           1            0       ...         Democratic  1961–1963   \n",
      "8          0           0            1       ...         Democratic  1961–1963   \n",
      "\n",
      "   state_of_birth  birth_date  death_date      religion_y  age_inauguration  \\\n",
      "8           Mass.   5/29/1917  11/22/1963  Roman Catholic                43   \n",
      "8           Mass.   5/29/1917  11/22/1963  Roman Catholic                43   \n",
      "8           Mass.   5/29/1917  11/22/1963  Roman Catholic                43   \n",
      "8           Mass.   5/29/1917  11/22/1963  Roman Catholic                43   \n",
      "\n",
      "   age_death  rank_aggregate      president_y  \n",
      "8         46               9  John F. Kennedy  \n",
      "8         46               9  John F. Kennedy  \n",
      "8         46               9  John F. Kennedy  \n",
      "8         46               9  John F. Kennedy  \n",
      "\n",
      "[4 rows x 22758 columns]\n"
     ]
    }
   ],
   "source": [
    "# Join aggregate rankings DataFrame\n",
    "df_all = pd.merge(df_merge_details, df_rankings, on=\"id\", how=\"left\", left_index=True)\n",
    "print df_all[df_all.religion_y == 'Roman Catholic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####<i>Step 3: Exploring the Aggregated Data - Plotting</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll use aggregate functions to explore and plot the data in order to see if we can coax out any potential trends in the data before applying any models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10b48f110>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEyCAYAAAAfnKCSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b49c410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Visualize the most commonly-used words in aggregate\n",
    "df_counts = pd.DataFrame(df.iloc[:,3:].apply(np.sum, axis=0), columns=['word_count'])\n",
    "df_counts_sorted = df_counts.sort(['word_count'], ascending = [0])[:20]\n",
    "\n",
    "df_counts_sorted.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "religion_y\n",
      "Baptist                     world\n",
      "Congregationalist      government\n",
      "Deist                       shall\n",
      "Disciples of Christ        people\n",
      "Episcopalian               states\n",
      "Methodist                  states\n",
      "Presbyterian           government\n",
      "Quaker                 government\n",
      "Reformed Dutch         government\n",
      "Roman Catholic                new\n",
      "Southern Baptist            world\n",
      "Unitarian                  states\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 2. Group DataFrame values by religion, then visualize most used words by each religious affiliation\n",
    "\n",
    "# First use groupby to create word counts by religion\n",
    "df_religion = df_merge_details.groupby('religion_y').sum()\n",
    "df_religion = df_religion.iloc[:, 1:-1]\n",
    "\n",
    "# Find the most used words by religious affiliation\n",
    "print df_religion.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "party_name\n",
      "Democratic               government\n",
      "Democratic Republican        states\n",
      "Federalist                   states\n",
      "Republican               government\n",
      "Union                        states\n",
      "Whig                     government\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 3. Group DataFrame values by party, then visualize most used words by each party\n",
    "\n",
    "# First use groupby to create word counts by party\n",
    "df_party = df_merge_details.groupby('party_name').sum()\n",
    "df_party = df_party.iloc[:, 1:-1]\n",
    "\n",
    "# Find the most used words by religious affiliation\n",
    "print df_party.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frankly speaking, we haven't gleaned anything really meaningful from exploring the data (at least in the ways above), so let's use a new tool - <b>Natural Language Processing</b> - to see if we can engineer some features that will make the trends in the data a little more apparent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####<i>Step 4: Exploring the Aggregated Data - Applying Natural Language Processing (NLP)</i> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll use some stemming modules from <b><code>NLTK</code></b> (specifically <b><code>PorterStemmer</code></b>) to reduce the number of features in the master <code>DataFrame</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12632\n"
     ]
    }
   ],
   "source": [
    "# Import PorterStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Instantiate a new PorterStemmer object\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Create Python list of tokens in DataFrame\n",
    "word_list = list(df_party.iloc[:,:].columns.values)\n",
    "\n",
    "# Use PorterStemmer to stem the tokens\n",
    "stems = [ps.stem(token) for token in word_list]\n",
    "stems_set = set(stems)\n",
    "\n",
    "print len(stems_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using <code>PorterStemmer</code>, we've effectively cut the number of features in half!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO(justindelatorre): How can we practically use Porter Stemming with the master data to cut out features?\n",
    "# - Might be worth stemming the tokens before adding to master DataFrame (would require re-work of data munging $%&!)\n",
    "# - Then, we can pass stems through LDA to get potentially more meaningful topic clusters\n",
    "# - Can also use grouped topics as features for Naïve Bayes modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##<i>Part III: Testing and Training Models</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####<i>Step 1: Implementing and Experimenting with LDA ([documentation](https://pypi.python.org/pypi/lda))</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another handy NLP application is <b>[latent Dirichlet allocation](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation) (LDA)</b>, which allows us to unearth hidden topics among the text we're examining. We can use this to potentially reduce our features even more, and in an even more meaningful way due to topic clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: states government united congress foreign shall treaty department state year time\n",
      "Topic 1: year states people legislation attention subject fiscal law congress number free\n",
      "Topic 2: world people great time nation way new hope right good come\n",
      "Topic 3: year world economic nations program free million dollars fiscal security war\n",
      "Topic 4: commerce citizens great attention intercourse treasury revenue vessels tribes object debt\n",
      "Topic 5: american international court canal law department men tariff navy proper commerce\n",
      "Topic 6: men man work business corporations law good far power need interstate\n",
      "Topic 7: war shall men peace american nations nation united life free let\n",
      "Topic 8: years reduction local prosperity general administration commission justice authority construction welfare\n",
      "Topic 9: federal new programs nation growth energy administration union percent years help\n",
      "Topic 10: america people americans work years new year let american children congress\n",
      "Topic 11: general government commission cuba american consideration products islands having gold international\n",
      "Topic 12: great service law people labor large purpose action country methods ought\n",
      "Topic 13: applause freedom america country security citizens ve free ll weapons tax\n",
      "Topic 14: people general government power subject constitution condition consideration character duties institutions\n",
      "Topic 15: states united great congress force powers year act war progress british\n",
      "Topic 16: government duty make interests lands present navy large different place army\n",
      "Topic 17: public country time state important citizens government laws means law best\n",
      "Topic 18: states mexico war constitution territory power great texas union treasury mexican\n",
      "Topic 19: government national congress federal work present action policy legislation war necessary\n"
     ]
    }
   ],
   "source": [
    "# Manipulate data so it can be passed through the LDA instance\n",
    "df_id_only = pd.concat([df.iloc[:,:1], df.iloc[:,3:]], axis=1)\n",
    "df_id_only_grouped = df_id_only.groupby('id').sum()\n",
    "\n",
    "# Turn the DataFrame into a matrix of numpy arrays, will serve as X in LDA\n",
    "df_matrix = df_id_only_grouped.as_matrix(columns=None)\n",
    "\n",
    "# Import LDA module\n",
    "import lda\n",
    "\n",
    "# Create new instance of LDA that will group into 20 topics\n",
    "# and cycle through 1000 iterations\n",
    "model = lda.LDA(n_topics=20, n_iter=1000, random_state=1)\n",
    "model.fit(df_matrix)\n",
    "topic_word = model.topic_word_\n",
    "n_top_words = 12\n",
    "\n",
    "# Note: word_list was generated in the above section on stemming\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(word_list)[np.argsort(topic_dist)][:-n_top_words:-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some semblance of topic clustering, we can use <code>lda</code>'s <b><code>doc\\_topic\\_</code></b> function to figure out the most prominent topic (based on the above list) that each president focused on within the corpus of all his speeches in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (top topic: 4)\n",
      "2 (top topic: 4)\n",
      "3 (top topic: 4)\n",
      "4 (top topic: 4)\n",
      "5 (top topic: 4)\n",
      "6 (top topic: 4)\n",
      "7 (top topic: 14)\n",
      "8 (top topic: 17)\n",
      "9 (top topic: 14)\n",
      "10 (top topic: 0)\n",
      "11 (top topic: 18)\n",
      "12 (top topic: 0)\n",
      "13 (top topic: 0)\n",
      "14 (top topic: 0)\n",
      "15 (top topic: 0)\n",
      "16 (top topic: 0)\n",
      "17 (top topic: 0)\n",
      "18 (top topic: 0)\n",
      "19 (top topic: 0)\n",
      "20 (top topic: 7)\n",
      "21 (top topic: 0)\n",
      "22 (top topic: 1)\n",
      "23 (top topic: 1)\n",
      "24 (top topic: 14)\n",
      "25 (top topic: 0)\n",
      "26 (top topic: 6)\n",
      "27 (top topic: 5)\n",
      "28 (top topic: 7)\n",
      "29 (top topic: 12)\n",
      "30 (top topic: 8)\n",
      "31 (top topic: 8)\n",
      "32 (top topic: 2)\n",
      "33 (top topic: 3)\n",
      "34 (top topic: 3)\n",
      "35 (top topic: 9)\n",
      "36 (top topic: 10)\n",
      "37 (top topic: 10)\n",
      "38 (top topic: 9)\n",
      "39 (top topic: 9)\n",
      "40 (top topic: 10)\n",
      "41 (top topic: 10)\n",
      "42 (top topic: 10)\n",
      "43 (top topic: 13)\n"
     ]
    }
   ],
   "source": [
    "# Find the most prevalent topic among each president's collection of speeches\n",
    "\n",
    "# Create list of president IDs\n",
    "prez_ids = df_id_only_grouped.index\n",
    "\n",
    "doc_topic = model.doc_topic_\n",
    "for i in range(len(prez_ids)):\n",
    "    print(\"{} (top topic: {})\".format(prez_ids[i], doc_topic[i].argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results above, using LDA (at least on all the tokens, rather than a potentially more meaningful subset) gives us a slightly better look at any trends in all of the presidential speeches we're examining, but nothing glaringly meaningful sticks out just yet.\n",
    "\n",
    "Let's move on to using Naïve Bayes, where we hope to be able to predict, at least with some level of accuracy higher than a coin flip, the likelihood that a president is either of a certain party or religious affiliation based on the themes and words in the speeches, and if certain words and themes are predictive of our more highly-regarded presidents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####<i>Step 2: Probabilities, Predictions, and Presidents with Naïve Bayes</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####<i>Step 3: Using Outside Data</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, there are limited full-text transcripts of speeches from the fake presidents - Jed Bartlett and Matt Santos from <i>The West Wing</i> - I wanted to run through the trained model. But, I've worked really hard to get to this point, so I'd like to at least see how good the model is, given that we know both president's outcome labels (both presidents were Roman Catholics and Democrats).\n",
    "\n",
    "Knowing that, I will march on and use any available text from the show transcripts in which either president gave some sort of speech. I know this is technically not the way to go given the model was trained and tested using specifically Inaugural Address and State of the Union text, but this is my project, so sue me :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load text into memory for data wrangling\n",
    "\n",
    "# Create arrays and DataFrames for each West Wing president\n",
    "\n",
    "# Apply the trained Naïve Bayes model to the aggregate text for each president"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##<i>Part IV: Conclusions</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
