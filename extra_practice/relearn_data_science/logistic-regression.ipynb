{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite its name, [logistic (logit) regression](http://en.wikipedia.org/wiki/Logistic_regression) is actually a classification algorithm, not a regression model. The \"regression\" part comes from the fact that it attempts to fit a linear model to the feature space; it is thus a generalization of the linear regression model to classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general goal of logistic regression is to learn to correctly classify binary classes, where $Y = \\{0, 1\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that in a linear regression, we used a set of covariates to predict the value of a **continuous** outcome variable.\n",
    "\n",
    "In a logistic regression, we will use a set of covariates **to predict the probabilities of binary class membership**. The probabilities are then mapped to class labels, thus solving the classification problem.\n",
    "\n",
    "For example, if we determine that the probability of being either male or female for a record is 0.55, and anything over 0.50 is male, then we can state with some confidence that the record in question is male according to logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another key difference between a linear and logistic regression is that in a linear model, we assume that the outcome values can go from $(-\\infty, +\\infty)$. In a logistic regression, we need to map the outcome values to the unit interval $[0, 1]$. We do this by using a transformation call the **logistic function**:\n",
    "\n",
    "$$f(x) = \\frac{e^x}{e^x + 1} = \\frac{1}{1 + e^{-x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic function can also be transformed into a linear version called the **logit (log-odds) function**:\n",
    "\n",
    "$$g(x) = ln(\\frac{\\pi(x)}{1-\\pi(x)}) = \\alpha + \\beta x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the logistic function:\n",
    "<ol>\n",
    "<li>Model consists of a vector $\\beta$ in d-dimensional feature space</li>\n",
    "<li>For a point $x$, project it onto $\\beta$ to convert it into a real number $z$ in the range $(-\\infty, +\\infty)$</li>\n",
    "\n",
    "$$z = \\alpha + \\beta \\bullet x = \\alpha + \\beta_1 x_1 + ... + \\beta_d x_d$$\n",
    "\n",
    "<li>Map $z$ to the range $[0,1]$ using the logistic function</li>\n",
    "\n",
    "$$p = \\frac{1}{1 + e^{-z}}$$\n",
    "</ol>\n",
    "\n",
    "The resulting prediction is presented as a **probability of class membership**.\n",
    "\n",
    "When you train the data, you'll need to optimize $\\beta$ so the model gives the best possible reproduction of training set labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note about $f(x) = \\alpha + \\beta x$:\n",
    "\n",
    "<img src=\"logistic_function_graph.png\">\n",
    "\n",
    "<ul>\n",
    "<li>$\\alpha$ controls the location of the midpoint</li>\n",
    "<li>$\\beta$ controls the slope of the rise</li>\n",
    "</ul>\n",
    "\n",
    "<img src=\"logistic_function_graph_compare.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Titanic: Revisited\n",
    "\n",
    "Let's explore logistic regression by applying it to the Titanic dataset.\n",
    "\n",
    "As always, let's start by importing the correct packages and the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Survived.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without modeling the data, what is our prediction benchmark?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.383838383838\n",
      "0.616161616162\n"
     ]
    }
   ],
   "source": [
    "print data.Survived.mean()\n",
    "print 1 - data.Survived.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like 2/3 of the passengers perished based on the above data. This simple model would reach around 62% predictive accuracy (Why?), which is higher than predicting at random (50%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set the target values to the <code>Survived</code> values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = data.Survived.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>sklearn</code> estimators all work with homogeneous numerical features descriptors passed as a <code>numpy</code> array, so passing a raw DataFrame won't work.\n",
    "\n",
    "We'll begin by building a model that only uses numerical features as input, like <code>data.Fare</code>, <code>data.Pclass</code>, and <code>data.Age</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>  7.2500</td>\n",
       "      <td> 3</td>\n",
       "      <td> 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 71.2833</td>\n",
       "      <td> 1</td>\n",
       "      <td> 38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>  7.9250</td>\n",
       "      <td> 3</td>\n",
       "      <td> 26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 53.1000</td>\n",
       "      <td> 1</td>\n",
       "      <td> 35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>  8.0500</td>\n",
       "      <td> 3</td>\n",
       "      <td> 35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fare  Pclass  Age\n",
       "0   7.2500       3   22\n",
       "1  71.2833       1   38\n",
       "2   7.9250       3   26\n",
       "3  53.1000       1   35\n",
       "4   8.0500       3   35"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features = data.get(['Fare', 'Pclass', 'Age'])\n",
    "numerical_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at all the data, however, we'll see that some passenger records (~177) don't have age information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fare      891\n",
       "Pclass    891\n",
       "Age       714\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the pandas <code>fillna</code> method to input the median age for those passengers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fare      15.7417\n",
       "Pclass     2.0000\n",
       "Age       28.0000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_features = numerical_features.dropna().median()\n",
    "median_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fare      891\n",
       "Pclass    891\n",
       "Age       891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_features = numerical_features.fillna(median_features)\n",
    "imputed_features.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>  7.2500</td>\n",
       "      <td> 3</td>\n",
       "      <td> 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 71.2833</td>\n",
       "      <td> 1</td>\n",
       "      <td> 38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>  7.9250</td>\n",
       "      <td> 3</td>\n",
       "      <td> 26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 53.1000</td>\n",
       "      <td> 1</td>\n",
       "      <td> 35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>  8.0500</td>\n",
       "      <td> 3</td>\n",
       "      <td> 35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fare  Pclass  Age\n",
       "0   7.2500       3   22\n",
       "1  71.2833       1   38\n",
       "2   7.9250       3   26\n",
       "3  53.1000       1   35\n",
       "4   8.0500       3   35"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame is now clean and can be converted into a homogeneous <code>numpy</code> array of floating point values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.25  ,   3.    ,  22.    ],\n",
       "       [ 71.2833,   1.    ,  38.    ],\n",
       "       [  7.925 ,   3.    ,  26.    ],\n",
       "       ..., \n",
       "       [ 23.45  ,   3.    ,  28.    ],\n",
       "       [ 30.    ,   1.    ,  26.    ],\n",
       "       [  7.75  ,   3.    ,  32.    ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_array = imputed_features.values\n",
    "features_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take 80% of the data to train the first model and keep the remaining 20% for computing the generalization score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features_array, target, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now initialize a <code>LogisticRegression</code> instance from scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the <code>predict</code> function and pass through the <code>features_test</code> data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_predicted = lr.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pass in the <code>target_test</code> and <code>target_predicted</code> data into the <code>accuracy_score</code> function to get the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73184357541899436"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(target_test, target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instance of the model is ~73% accurate, which is better than our previous baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Model Evaluation and Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <code>coef_</code> attribute of a fitted linear model like <code>LogisticRegression</code> holds the weights ($\\beta_1, \\beta_2, ..., \\beta_n$) of each feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fare', 'Pclass', 'Age'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = numerical_features.columns.values\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0043996 , -0.80916725, -0.03348064]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a simple plot to help illustrate the relationship between each feature and the possible outcomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEJCAYAAABv6GdPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZNwlqUHGXZIaZNwlqUH/B20Xy1kH0Cg8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1084e7c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(feature_names))\n",
    "plt.bar(x, lr.coef_.ravel()) # What does .ravel() do?\n",
    "_ = plt.xticks(x + 0.5, feature_names, rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the graph above, it looks like <code>Fare</code> is slightly positively correlated with survival (i.e., the higher the fare, the higher the likelihood of survival, according to the model), while lower class and older passengers are more likely to die (negative correlation between <code>Pclass</code> and survival and <code>Age</code> and survival), which makes sense based on historical accounts of the disaster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Predicting Probabilities of Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since logistic regression is a probabilistic model, it does more than just predict a binary outcome (in this case, survived or not) given the input features; it can also estimate the posterior probability of the outcome given the input features (remember **Naïve Bayes**?) using the <code>predict_proba</code> method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.75263264,  0.24736736],\n",
       "       [ 0.75824771,  0.24175229],\n",
       "       [ 0.58542437,  0.41457563],\n",
       "       [ 0.25224882,  0.74775118],\n",
       "       [ 0.75817844,  0.24182156]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_predicted_proba = lr.predict_proba(features_test)\n",
    "target_predicted_proba[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision threshold is 0.5 by default, but we can vary that value from 0 to 1 in order to change the model to address trade-offs between false positive and false negative prediction errors.\n",
    "\n",
    "Let's build a confusion matrix to track the false positives and false negatives that occurred in this version of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98 12]\n",
      " [36 33]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(target_test, target_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, it looks like the model incorrectly classified 12 deceased passengers as survivors, and 36 surviving passengers as deceased.\n",
    "\n",
    "Another way to check the quality of a binary classifier on imbalanced (?) data is to compute the <code>precision</code>, <code>recall</code> and <code>f1-score</code> of a model (at the default decision threshold of 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "not_survived       0.73      0.89      0.80       110\n",
      "    survived       0.73      0.48      0.58        69\n",
      "\n",
      " avg / total       0.73      0.73      0.72       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(target_test, target_predicted,\n",
    "                            target_names=['not_survived', 'survived']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Further Questions\n",
    "<ol>\n",
    "<li>What does \"imbalanced data\" mean?</li>\n",
    "<li>What do <code>recall</code> and <code>f1-score</code> represent?</li>\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
